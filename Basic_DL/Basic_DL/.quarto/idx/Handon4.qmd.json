{"title":"Define a transform to normalize the data","markdown":{"headingText":"Define a transform to normalize the data","containsRefs":false,"markdown":"\n```{python}\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n```\n\n\n\n```{python,echo = FALSE }\n\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Load the training and test datasets\ntrainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n\ntestset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n\n\n```\n\n\n\n\n\n```{python}\n\ndef imshow(img):\n    img = img / 2 + 0.5  # Unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n# Get some random training images\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# Plot 20 images in a 4x5 grid\nfig, axes = plt.subplots(nrows=4, ncols=5, figsize=(10, 10))\naxes = axes.flatten()\n\nfor idx, ax in enumerate(axes):\n    if idx < len(images):\n        ax.imshow(images[idx].numpy().squeeze(), cmap='gray')\n        ax.set_title(f'Label: {labels[idx].item()}')\n        ax.axis('off')\n    else:\n        ax.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n```\n\n\n\n```{python}\n\n# Define the Neural Network\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28*28, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 128)\n        self.fc4 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 28*28)  # Flatten the image\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = torch.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\n\nnet = Net()\n\n```\n\n\n```{python}\n# Define the Loss Function and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\n```\n\n\n```{python}\n# Lists to keep track of losses\ntrain_losses = []\ntest_losses = []\n\nfor epoch in range(10):  # Loop over the dataset multiple times\n    running_loss = 0.0\n    net.train()  # Set the network to training mode\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        # Print statistics\n        running_loss += loss.item()\n        if i % 100 == 99:    # Print every 100 mini-batches\n            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n            running_loss = 0.0\n\n    # Track training loss\n    train_losses.append(loss.item())\n\n    # Track test loss\n    net.eval()  # Set the network to evaluation mode\n    test_loss = 0.0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            outputs = net(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n    test_losses.append(test_loss / len(testloader))\n\nprint('Finished Training')\n\n```\n\n\n```{python}\n# Plot the training and test losses\nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label='Training Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Test Loss')\nplt.legend()\nplt.show()\n\n```\n\n\n```{python}\n# Test the Network\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"Handon4.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","editor":"visual","theme":"cosmo"},"extensions":{"book":{"multiFile":true}}}}}